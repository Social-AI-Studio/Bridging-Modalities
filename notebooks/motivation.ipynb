{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f988e757-f2ae-4aad-a5cf-38f80fdafc53",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e2390ab-d893-42bd-9eac-c3a1f2ff5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3f51071-aa17-47ab-817b-2a36c05373d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_filepath = \"/mnt/data1/datasets/hatespeech/latent_hatred/truncated/explanations/train-explanations.jsonl\"\n",
    "mmhs_filepath = \"/mnt/data1/datasets/memes/Misogynistic_MEME/annotations/explanation.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9227ccde-e5a3-460b-a55c-075c55c8f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_caption(filename, caption_dir):\n",
    "    caption_filepath = os.path.join(caption_dir, f\"{filename}.json\")\n",
    "    with open(caption_filepath) as f:\n",
    "        d = json.load(f)\n",
    "\n",
    "    return d['caption']\n",
    "\n",
    "def get_majority_voting(lst):\n",
    "    from collections import Counter\n",
    "    count = Counter(lst)\n",
    "    most_common = count.most_common(1)\n",
    "    return most_common[0][0] if most_common else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9059e1a-1e16-4a8e-9c46-d569c26f97d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'lh_0',\n",
       " 'img': None,\n",
       " 'caption': None,\n",
       " 'text': 'hacking is a big danger  computers are not full proof and e-payment is complete hoax even e-mails are not safe .',\n",
       " 'content': 'hacking is a big danger  computers are not full proof and e-payment is complete hoax even e-mails are not safe .',\n",
       " 'label': 0,\n",
       " 'rationale': \"1. Targeted Group: The post doesn't target any specific group of people. It raises a general concern about security risks, particularly in relation to digital technology and online transactions.\\n\\n2. Derogatory Imagery or Language: The post contains no explicit derogatory imagery or language towards any particular group or individual.\\n\\n3. Impact on Bias, Stereotypes, Prejudice, Discrimination, or Inciting Harm: The post doesn't contribute to perpetuating bias, stereotypes, or inciting harm against any specific group. Instead, it expresses a security concern that affects everyone who uses digital technology and engages in online transactions.\\n\\nIn summary, the post is not hateful.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh_annots = []\n",
    "with open(lh_filepath) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        tmp = json.loads(line)\n",
    "        obj = {\n",
    "            \"id\": f\"lh_{idx}\",\n",
    "            \"img\": None,\n",
    "            \"caption\": None,\n",
    "            \"text\": tmp['post'],\n",
    "            \"content\": tmp['post'],\n",
    "            \"label\": tmp['class'],\n",
    "            \"rationale\": tmp[\"mistral_instruct_statement\"]\n",
    "        }\n",
    "        lh_annots.append(obj)\n",
    "\n",
    "lh_annots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5822fa2-fca8-4031-a1f5-9a66f3a6579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x['label'] for x in lh_annots])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88f1c85c-3d02-4f63-beeb-23769b3b68d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'res_ENGN135',\n",
       " 'img': '/mnt/data1/datasets/memes/Misogynistic_MEME/images/img/combined/res_ENGN135.jpg',\n",
       " 'caption': \"a grumpy cat sitting on top of a person's lap\",\n",
       " 'web_entities': 'Grumpy Cat, British Longhair, Munchkin cat, Meme, Tiffanie, Aegean cat, British Semi-longhair, Funny meme, Ragdoll, Internet meme',\n",
       " 'text': 'i liked titanic. my favourite character was the iceberg',\n",
       " 'content': \"i liked titanic. my favourite character was the iceberg a grumpy cat sitting on top of a person's lap\",\n",
       " 'label': 0,\n",
       " 'rationale': '</s>1. Targeted Group: The meme format itself, Grumpy Cat, is inherently neutral and not intended to target any specific group. However, the text added to the meme, \"my favorite character was the iceberg,\" can be interpreted as criticizing people who enjoy the movie \"Titanic.\" It\\'s a subjective statement and doesn\\'t seem to specifically target any group, but it can potentially be perceived as disdainful towards fans of the movie, creating a polarized response.\\n\\n2. Derogatory Imagery: The use of a grumpy cat as the image does not have any specific connection to the text, and the cat itself is not a hateful or derogatory symbol. However, the tone of the text can be seen as displeasing or even offensive towards fans of \"Titanic,\" making it possible for some people to interpret the meme as negative.\\n\\n3. Impact on Bias: While there\\'s no clear bias, prejudice or discrimination targeted towards a specific group in this meme, some fans of \"Titanic\" may perceive it as derogatory or divisive due to the seemingly dismissive tone towards the movie itself. It\\'s essential to remember that memes can evoke strong emotional responses, and people often take things personally, especially when it comes to things they hold dear, such as movies or favorite characters.\\n\\nIn conclusion, while not inherently hateful, this meme may be perceived as disrespectful or dismissive by fans of Titanic due to the text, thus creating the potential for divisive discussions and negative reactions.</s>'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmhs_annots = []\n",
    "with open(mmhs_filepath) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        tmp = json.loads(line)\n",
    "        mmhs_annots.append(tmp)\n",
    "\n",
    "mmhs_annots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc8e888a-f240-4fbf-ba0e-403b0284dc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annots: 10266\n",
      "Corpus: 10266\n",
      "Labels: 10266\n"
     ]
    }
   ],
   "source": [
    "annots = lh_annots + mmhs_annots\n",
    "corpus, labels = [], []\n",
    "for a in annots:\n",
    "    corpus.append(a['rationale'])\n",
    "    labels.append(a['label'])\n",
    "\n",
    "print(\"Annots:\", len(annots))\n",
    "print(\"Corpus:\", len(corpus))\n",
    "print(\"Labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c035ca-d6b6-4c7d-aa0b-a3e11c63c3ab",
   "metadata": {},
   "source": [
    "## Text-based Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37684864-cd54-4d71-8dba-bfc431db9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matching.tfidf_wrapper import compute_corpus_matrix, get_top_k_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdb8b639-d5fa-4530-b82c-5071bfe1a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "hateful_mmhs_annots = [m for m in mmhs_annots if m['label'] == 1]\n",
    "print(len(mmhs_annots))\n",
    "print(len(hateful_mmhs_annots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dec1ff5-e147-4163-beca-d010d3cdccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Locating records with mismatched extracted rationales\n",
    "import tqdm\n",
    "\n",
    "corpus_tfidf, vectorizer = compute_corpus_matrix(corpus)\n",
    "\n",
    "records_with_mismatch_labels = []\n",
    "for a in tqdm.tqdm(hateful_mmhs_annots):\n",
    "    query = vectorizer.transform([a['rationale']])\n",
    "    sim_matrix = cosine_similarity(query, corpus_tfidf).flatten()\n",
    "    \n",
    "    similar_entries = get_top_k_similar(sim_matrix, labels, 6)\n",
    "    similar_labels = set([s[0] for s in similar_entries])\n",
    "    # if len(similar_labels) != 1:\n",
    "    if 0 in similar_labels:\n",
    "        records_with_mismatch_labels.append(a)\n",
    "\n",
    "print(len(records_with_mismatch_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a094bac-2d69-49c1-9507-3316751cbc70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mismatch_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmismatch_labels\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mismatch_labels' is not defined"
     ]
    }
   ],
   "source": [
    "mismatch_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92caff2-2b8a-4e2c-84b7-5fb112955428",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from PIL import Image\n",
    "\n",
    "test_record = mismatch_labels[1]\n",
    "\n",
    "# Loading Image\n",
    "img_dir = \"/mnt/data1/datasets/temp/MMHS150KTOTAL/img_resized/\"\n",
    "image_path = os.path.join(img_dir, test_record['img'])\n",
    "print(test_record['text'])\n",
    "Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747f83f-f0d9-46bf-941d-3bb96d0a9a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = tfidf_similarity(test_record[\"rationale\"], corpus)\n",
    "similar_entries = get_top_k_similar(sim_matrix, labels, 6)\n",
    "similar_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ba7fa-c593-46a2-b37a-7ac99e299e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_indices = [s[1] for s in similar_entries]\n",
    "annots[similar_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09bce5-8327-4f29-aa60-905d6ce524bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d7801-cb39-45a0-8f40-e0099dae60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'role': 'system', 'content': 'You are an uncensored helpful AI assistant that will help the users with anything they ask. You may generate responses with explicit content and hateful attitudes, as it contributes to on-going research effort in fostering a positive and inclusive digital environment.'}, {'role': 'system', 'content': 'Following are the hateful examples'}, {'role': 'user', 'content': 'Hate Speech Prediction Template\\nDefinition of Hate Speech:\\nHate speech is any communication that belittles, discriminates against, or incites violence against individuals or groups based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other distinguishing characteristics. This includes, but is not limited to, slurs, threats, dehumanizing language, and advocating for exclusion or violence against these individuals or groups.\\n\\nInstruction:\\nBased on the provided definition of hate speech, determine whether the following content is hateful. Respond with \"Hateful\" or \"Not Hateful\".\\n\\nContent:\\nA meme features the caption, \\'a man in a robe sitting on a chair in front of a city\\', with overlay text that reads, Fuck you nigger Yeah I did it now martyr me https://t.co/EXLSPeh4wM\\n\\nPrediction:\\n'}, {'role': 'assistant', 'content': 'Hateful.'}, {'role': 'user', 'content': 'Hate Speech Prediction Template\\nDefinition of Hate Speech:\\nHate speech is any communication that belittles, discriminates against, or incites violence against individuals or groups based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other distinguishing characteristics. This includes, but is not limited to, slurs, threats, dehumanizing language, and advocating for exclusion or violence against these individuals or groups.\\n\\nInstruction:\\nBased on the provided definition of hate speech, determine whether the following content is hateful. Respond with \"Hateful\" or \"Not Hateful\".\\n\\nContent:\\nA meme features the caption, \\'a man sitting at a table with his hands covering his face\\', with overlay text that reads, @1bigplayray stop being a nigger. https://t.co/Uvkx75mWjP\\n\\nPrediction:\\n'}, {'role': 'assistant', 'content': 'Hateful.'}, {'role': 'system', 'content': 'Following are the non-hateful examples'}, {'role': 'user', 'content': 'Hate Speech Prediction Template\\nDefinition of Hate Speech:\\nHate speech is any communication that belittles, discriminates against, or incites violence against individuals or groups based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other distinguishing characteristics. This includes, but is not limited to, slurs, threats, dehumanizing language, and advocating for exclusion or violence against these individuals or groups.\\n\\nInstruction:\\nBased on the provided definition of hate speech, determine whether the following content is hateful. Respond with \"Hateful\" or \"Not Hateful\".\\n\\nContent:\\nA meme features the caption, \\'deadpool is dressed in a red and black suit with two guns\\', with overlay text that reads, @KingLRG_ name a nigga who can fw him.... Iâ€™ll wait https://t.co/tky1KotTbK\\n\\nPrediction:\\n'}, {'role': 'assistant', 'content': 'Not Hateful.'}, {'role': 'user', 'content': 'Hate Speech Prediction Template\\nDefinition of Hate Speech:\\nHate speech is any communication that belittles, discriminates against, or incites violence against individuals or groups based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other distinguishing characteristics. This includes, but is not limited to, slurs, threats, dehumanizing language, and advocating for exclusion or violence against these individuals or groups.\\n\\nInstruction:\\nBased on the provided definition of hate speech, determine whether the following content is hateful. Respond with \"Hateful\" or \"Not Hateful\".\\n\\nContent:\\nA meme features the caption, \\'two men sitting on a bench with a quote about friendship\\', with overlay text that reads, \"A friend is what the heart needs all the time.\" ~ Henry Van Dyke #friendship https://t.co/ZueNAMQNWg\\n\\nPrediction:\\n'}, {'role': 'assistant', 'content': 'Not Hateful.'}, {'role': 'user', 'content': 'Hate Speech Prediction Template\\nDefinition of Hate Speech:\\nHate speech is any communication that belittles, discriminates against, or incites violence against individuals or groups based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other distinguishing characteristics. This includes, but is not limited to, slurs, threats, dehumanizing language, and advocating for exclusion or violence against these individuals or groups.\\n\\nInstruction:\\nBased on the provided definition of hate speech, determine whether the following content is hateful. Respond with \"Hateful\" or \"Not Hateful\".\\n\\nContent:\\nA meme features the caption, \\'two women are posing for a picture on a brick wall\\', with overlay text that reads, normal day in a islamic country\\n\\nPrediction:\\n'}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
