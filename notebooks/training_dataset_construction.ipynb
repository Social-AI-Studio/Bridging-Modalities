{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8e7588-6353-47af-8ae6-23578124d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13f7cc7-c1b0-4ea0-a9d5-3fb24422464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_filepath = \"/mnt/data1/datasets/hatespeech/latent_hatred/truncated/explanations-revised/train-explanations.jsonl\"\n",
    "\n",
    "misogynistic_filepath = \"/mnt/data1/datasets/memes/Misogynistic_MEME/annotations/explanation.jsonl\"\n",
    "misogynistic_features_dir = \"/mnt/data1/datasets/memes/cmtl-rag/mmhs/embeddings/clip-ViT-B-32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfa378d-f931-4930-9dbd-f7e8c06a778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_caption(filename, caption_dir):\n",
    "    caption_filepath = os.path.join(caption_dir, filename)\n",
    "    with open(caption_filepath) as f:\n",
    "        d = json.load(f)\n",
    "\n",
    "    return d['caption']\n",
    "\n",
    "\n",
    "def load_features(features_dir, filename):\n",
    "    # Iterate over all files in the folder\n",
    "    file_path = os.path.join(features_dir, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_majority_voting(lst):\n",
    "    from collections import Counter\n",
    "    count = Counter(lst)\n",
    "    most_common = count.most_common(1)\n",
    "    return most_common[0][0] if most_common else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5eaed20-45f2-4554-a8f2-b34b18528b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Targets: 326\n",
      "Number of Targets Mappings: 8\n",
      "Targets Mappings: {'political', 'religion', 'sex', 'others', 'nationality', 'organisations', 'race', 'disability'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"lh_target_mapping.json\") as f:\n",
    "    target_mapping = json.load(f)\n",
    "\n",
    "print(\"Number of Targets:\", len(target_mapping))\n",
    "print(\"Number of Targets Mappings:\", len(set(target_mapping.values())))\n",
    "print(\"Targets Mappings:\", set(target_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c23fbd6-50f3-423b-ba77-3345366c35d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'lh_803579998141452288',\n",
       " 'img': None,\n",
       " 'caption': None,\n",
       " 'text': 'hacking is a big danger  computers are not full proof and e-payment is complete hoax even e-mails are not safe .',\n",
       " 'label': 0,\n",
       " 'implicit_class': None,\n",
       " 'target': None,\n",
       " 'target_category': None,\n",
       " 'rationale': \"1. Targeted Group: The post doesn't target any specific group of people. It raises a general concern about security risks, particularly in relation to digital technology and online transactions.\\n\\n2. Derogatory Imagery or Language: The post contains no explicit derogatory imagery or language towards any particular group or individual.\\n\\n3. Impact on Bias, Stereotypes, Prejudice, Discrimination, or Inciting Harm: The post doesn't contribute to perpetuating bias, stereotypes, or inciting harm against any specific group. Instead, it expresses a security concern that affects everyone who uses digital technology and engages in online transactions.\\n\\nIn summary, the post is not hateful.\",\n",
       " 'features': 'N/A'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh_annots = []\n",
    "with open(lh_filepath) as f:\n",
    "    for line in f:\n",
    "        tmp = json.loads(line)\n",
    "        obj = {\n",
    "            \"id\": f\"lh_{tmp['ID']}\",\n",
    "            \"img\": None,\n",
    "            \"caption\": None,\n",
    "            \"text\": tmp['post'],\n",
    "            \"label\": tmp['class'],\n",
    "            \"implicit_class\": tmp['implicit_class'],\n",
    "            \"target\": tmp['target'],\n",
    "            \"target_category\": target_mapping[tmp['target'].lower().replace('\"', \"'\")] if tmp['target'] else None,\n",
    "            \"rationale\": tmp[\"mistral_instruct_statement\"],\n",
    "            \"features\": \"N/A\"\n",
    "        }\n",
    "        lh_annots.append(obj)\n",
    "\n",
    "lh_annots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c687493-aa8b-47d1-b95f-1271d48ad9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Targets: 326\n"
     ]
    }
   ],
   "source": [
    "target_list = set([x['target'] for x in lh_annots])\n",
    "target_list.remove(None)\n",
    "target_list = set([x.lower() for x in target_list])\n",
    "print(\"Number of Targets:\", len(target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32f3b21-d95e-4a81-b5d1-30f5d434932e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set([x['label'] for x in lh_annots])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25c02f9-ddac-4d1c-9f89-790ddfcc15f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'res_ENG01',\n",
       " 'img': '/mnt/data1/datasets/memes/Misogynistic_MEME/images/img/combined/res_ENG01.jpg',\n",
       " 'caption': 'a man and a woman in a red convertible car',\n",
       " 'web_entities': 'Car, Misogyny, Meme, Shelby Mustang, Ford Mustang, Internet meme, Text, Driving, Automatic Transmission, Manual Transmission',\n",
       " 'text': 'The way every man feels when a woman is driving',\n",
       " 'content': 'The way every man feels when a woman is driving a man and a woman in a red convertible car',\n",
       " 'label': 1,\n",
       " 'rationale': '</s> Targeted Group: Despite the lack of explicit reference to any specific group, the meme conveys a negative perception of women drivers, and as such, implicitly targets women as a group. \\n\\nDerogatory Imagery/Language: The statement \"The way every man feels when a woman is driving\" implies that women drivers cause negative feelings in men, creating an unnecessary and derogatory association between gender and driving ability.\\n\\nImpact on Bias/Stereotypes: The meme reinforces the harmful stereotype that women possess inferior driving skills, making it an example of Misogyny. Such portrayals have a negative impact on how women are perceived in society, and perpetuate biases and discrimination. \\n\\nIn summary, this meme is hateful because it targets the entire female population, and through its use of negative stereotypes and derogatory imagery, it perpetuates gender-based biases and discrimination.</s>',\n",
       " 'content_for_retrieval': 'The way every man feels when a woman is driving a man and a woman in a red convertible car',\n",
       " 'target': 'misogyny',\n",
       " 'target_category': 'sex'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misogynistic_annots = []\n",
    "with open(misogynistic_filepath) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        tmp = json.loads(line)\n",
    "        tmp['content_for_retrieval'] = tmp['content']\n",
    "        tmp['target'] = \"misogyny\"\n",
    "        tmp[\"target_category\"] = \"sex\"\n",
    "        misogynistic_annots.append(tmp)\n",
    "\n",
    "misogynistic_annots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71762d01-599e-42e1-9d5f-886f0c8aa20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set([x['label'] for x in misogynistic_annots])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd92430e-4244-44f7-8eb5-942f74e8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in meme_templates.items():\n",
    "#     print(k, v[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fffa6-45e1-4192-8046-761b8b9d12d9",
   "metadata": {},
   "source": [
    "### 1 - Rationale Similarity Matching\n",
    "\n",
    "Use TF-IDF to find tweets that are of similar explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e855e43-4884-478a-a94b-84976f019db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annots: 10800\n",
      "Corpus: 10800\n",
      "Labels: 10800\n"
     ]
    }
   ],
   "source": [
    "annots = lh_annots + misogynistic_annots\n",
    "corpus, labels = [], []\n",
    "for a in annots:\n",
    "    corpus.append(a['rationale'].strip())\n",
    "    labels.append(1 if a['label'] >= 1 else 0)\n",
    "\n",
    "print(\"Annots:\", len(annots))\n",
    "print(\"Corpus:\", len(corpus))\n",
    "print(\"Labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78cea827-d008-465e-b414-0baaf8ec506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matching.tfidf_wrapper import compute_corpus_matrix, get_top_k_similar, get_top_k_dissimilar\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e0b66e-7185-4df0-93e5-ac38072724c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Matrix: (10800, 15962)\n"
     ]
    }
   ],
   "source": [
    "corpus_matrix, vectorizer = compute_corpus_matrix(corpus)\n",
    "print(\"Corpus Matrix:\", corpus_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f8a91c1-346b-4d92-8e23-f077c8c6f8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrices: (10800, 10800)\n"
     ]
    }
   ],
   "source": [
    "sim_matrix = cosine_similarity(corpus_matrix, corpus_matrix)\n",
    "print(\"Similarity Matrices:\", sim_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6686d9-8f2b-4665-b4a4-09ba47431c43",
   "metadata": {},
   "source": [
    "### 2 - Stage 1 Training (Tweets Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958e75e9-2a90-46d1-9711-d1b1085665c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'lh_803579998141452288',\n",
       " 'img': None,\n",
       " 'caption': None,\n",
       " 'text': 'hacking is a big danger  computers are not full proof and e-payment is complete hoax even e-mails are not safe .',\n",
       " 'label': 0,\n",
       " 'implicit_class': None,\n",
       " 'target': None,\n",
       " 'target_category': None,\n",
       " 'rationale': \"1. Targeted Group: The post doesn't target any specific group of people. It raises a general concern about security risks, particularly in relation to digital technology and online transactions.\\n\\n2. Derogatory Imagery or Language: The post contains no explicit derogatory imagery or language towards any particular group or individual.\\n\\n3. Impact on Bias, Stereotypes, Prejudice, Discrimination, or Inciting Harm: The post doesn't contribute to perpetuating bias, stereotypes, or inciting harm against any specific group. Instead, it expresses a security concern that affects everyone who uses digital technology and engages in online transactions.\\n\\nIn summary, the post is not hateful.\",\n",
       " 'features': 'N/A'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh_annots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8c92c-1f15-4004-9888-042ce98954ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8203it [00:49, 170.13it/s]"
     ]
    }
   ],
   "source": [
    "# Locating records with mismatched extracted rationales\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def get_strong_positives(record, sim_vector, annots, k):\n",
    "    positives = {\n",
    "        \"pos_indices\": [],\n",
    "        \"pos_confidence\": []\n",
    "    }\n",
    "    indices = sim_vector.argsort()[::-1] # High confidence first\n",
    "    for ind in indices:\n",
    "        ind = int(ind)\n",
    "        confid = sim_vector[ind]\n",
    "        annot = annots[ind]\n",
    "\n",
    "        if record['target_category']:\n",
    "            if record['target_category'] == annot['target_category']:\n",
    "                positives['pos_indices'].append(ind)\n",
    "                # positives['pos_confidence'].append(confid)\n",
    "        else:\n",
    "            if record['label'] == annot['label']:\n",
    "                positives['pos_indices'].append(ind)\n",
    "                # positives['pos_confidence'].append(confid)\n",
    "\n",
    "        if len(negatives['pos_indices']) == k:\n",
    "            break\n",
    "            \n",
    "    return positives\n",
    "\n",
    "def get_strong_negatives(record, sim_vector, annots, k):\n",
    "    negatives = {\n",
    "        \"neg_indices\": [],\n",
    "        \"neg_confidence\": []\n",
    "    }\n",
    "    indices = sim_vector.argsort()[::] # Low confidence first\n",
    "    for ind in indices:\n",
    "        ind = int(ind)\n",
    "        confid = sim_vector[ind]\n",
    "        annot = annots[ind]\n",
    "\n",
    "        if record['target_category']:\n",
    "            if record['target_category'] != annot['target_category']:\n",
    "                negatives['neg_indices'].append(ind)\n",
    "                negatives['neg_confidence'].append(confid)\n",
    "        else:\n",
    "            if record['label'] != annot['label']:\n",
    "                negatives['neg_indices'].append(ind)\n",
    "                negatives['neg_confidence'].append(confid)\n",
    "\n",
    "        if len(negatives['neg_indices']) == k:\n",
    "            break\n",
    "    return negatives\n",
    "    \n",
    "\n",
    "training_records = {}\n",
    "for idx, record in tqdm.tqdm(enumerate(lh_annots)):\n",
    "    sim_vector = sim_matrix[idx]\n",
    "    sim_vector = np.concatenate((sim_vector[0:idx], sim_vector[idx + 1:10000]))\n",
    "    sim_annots = lh_annots[0:idx] + lh_annots[idx + 1:10000]\n",
    "    \n",
    "    pos = get_strong_positives(record, sim_vector, sim_annots)\n",
    "    negs = get_strong_negatives(record, sim_vector, sim_annots)\n",
    "    demonstrations = {**pos, **negs}\n",
    "\n",
    "    key = record['id']\n",
    "    training_records[key] = demonstrations\n",
    "\n",
    "print(len(training_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da836b-d665-410c-ac03-200b1942c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d5be8-65e9-4e57-af77-149ba8f5f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/stage1_training.json\", \"w+\") as f:\n",
    "    json.dump(training_records, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c0ae3-691a-4e5e-aef2-11c72b4bf43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287c975-d37a-4426-bb73-c8d13e6c9edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31536246-f74c-4066-b79a-48fb09d28029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7dc882-335d-44e3-9b1b-4b8f2a41cbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
